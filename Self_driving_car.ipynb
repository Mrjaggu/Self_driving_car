{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Importing prequiste</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "vgcc6iQobKHi"
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "import os\n",
    "import random\n",
    "import cv2\n",
    "import math\n",
    "import numpy as np\n",
    "from scipy import pi\n",
    "import scipy\n",
    "import scipy.misc\n",
    "\n",
    "from subprocess import call\n",
    "from datetime import datetime\n",
    "from itertools import islice\n",
    "import matplotlib.pyplot as plt \n",
    "import tensorflow as tf          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> EDA</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_data = [] #specifing for image data\n",
    "angle_data = [] #specifing for angle steering wheel data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining function to load our datas from data.txt\n",
    "def load_dataset():\n",
    "    #reading data from data.txt\n",
    "    with open(\"driving_dataset/data.txt\") as file:\n",
    "        for lines in file:\n",
    "            img_data.append('driving_dataset/' + lines.split()[0])\n",
    "            # the paper by Nvidia uses the inverse of the turning radius,\n",
    "            # but steering wheel angle is proportional to the inverse of turning radius\n",
    "            # so the steering wheel angle in radians is used as the output\n",
    "            angle_data.append(float(lines.split()[1])*scipy.pi/180)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dataset()\n",
    "\n",
    "#splitting datas into train and test 70-30 \n",
    "train_images = img_data[:int(len(img_data)*0.7)]\n",
    "train_angle = angle_data[:int(len(angle_data)*0.7)]\n",
    "\n",
    "test_images = img_data[-int(len(img_data)*0.3):]\n",
    "test_angle = angle_data[-int(len(angle_data)*0.3):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Total number of images: ', 45406)\n",
      "('Total number of images for training: ', 31784)\n",
      "('Total number of images for testing: ', 13621)\n"
     ]
    }
   ],
   "source": [
    "num_of_images = len(img_data)\n",
    "print(\"Total number of images: \",num_of_images)\n",
    "\n",
    "num_of_train_images = len(train_images)\n",
    "print(\"Total number of images for training: \",num_of_train_images)\n",
    "\n",
    "num_of_test_images = len(test_images)\n",
    "print(\"Total number of images for testing: \",num_of_test_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Histogram</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy;\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# PDF of train and test 'y' values. \n",
    "import matplotlib.pyplot as plt \n",
    "plt.figure(figsize=(10,8))\n",
    "plt.hist(train_angle, bins=50, normed=1, color='green', histtype ='step',label='Train angle');\n",
    "plt.hist(test_angle, bins=50, normed=1, color='red', histtype ='step',label='Test angle');\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Baseline Model </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test_MSE(MEAN):0.241559\n",
      "Test_MSE(ZERO):0.241108\n"
     ]
    }
   ],
   "source": [
    "#Model 0: Base line Model: y_test_pred = mean(y_train_i) \n",
    "train_mean_y = np.mean(train_angle)\n",
    "\n",
    "print('Test_MSE(MEAN):%f' % np.mean(np.square(test_angle-train_mean_y)) )\n",
    "\n",
    "print('Test_MSE(ZERO):%f' % np.mean(np.square(np.array(test_angle)-0)) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "As we can we are getting MSE around 0.223 for train and test split 70-30 i.e which is more then 0.19 that we have got for 80-20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Intializing weight , bias and convolution layer </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining function for weight\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    #The generated values follow a normal distribution with specified mean and standard deviation, \n",
    "    #except that values whose magnitude is more than 2 standard deviations from the mean are dropped and re-picked\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "#defining function for bias\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "#defining function for convolution layer parameter\n",
    "def conv2d(x, W, stride):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, stride, stride, 1], padding='VALID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_image_ln = tf.placeholder(tf.float32, shape=[None, 66, 200, 3],name=\"true_image_ln\")\n",
    "true_angle_ln = tf.placeholder(tf.float32, shape=[None, 1],name=\"true_angle_ln\")\n",
    "\n",
    "x_image_ln = true_image_ln"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first convolutional layer\n",
    "W_conv1_ln = weight_variable([5, 5, 3, 24])\n",
    "b_conv1_ln = bias_variable([24])\n",
    "\n",
    "h_conv1_ln = tf.nn.relu(conv2d(x_image_ln, W_conv1_ln, 2) + b_conv1_ln)\n",
    "\n",
    "#second convolutional layer\n",
    "W_conv2_ln = weight_variable([5, 5, 24, 36])\n",
    "b_conv2_ln = bias_variable([36])\n",
    "\n",
    "h_conv2_ln = tf.nn.relu(conv2d(h_conv1_ln, W_conv2_ln, 2) + b_conv2_ln)\n",
    "\n",
    "#third convolutional layer\n",
    "W_conv3_ln = weight_variable([5, 5, 36, 48])\n",
    "b_conv3_ln = bias_variable([48])\n",
    "\n",
    "h_conv3_ln = tf.nn.relu(conv2d(h_conv2_ln, W_conv3_ln, 2) + b_conv3_ln)\n",
    "\n",
    "#fourth convolutional layer\n",
    "W_conv4_ln = weight_variable([3, 3, 48, 64])\n",
    "b_conv4_ln = bias_variable([64])\n",
    "\n",
    "h_conv4_ln = tf.nn.relu(conv2d(h_conv3_ln, W_conv4_ln, 1) + b_conv4_ln)\n",
    "\n",
    "#fifth convolutional layer\n",
    "W_conv5_ln = weight_variable([3, 3, 64, 64])\n",
    "b_conv5_ln = bias_variable([64])\n",
    "\n",
    "h_conv5_ln = tf.nn.relu(conv2d(h_conv4_ln, W_conv5_ln, 1) + b_conv5_ln)\n",
    "\n",
    "#FCL 1\n",
    "W_fc1_ln = weight_variable([1152, 1164])\n",
    "b_fc1_ln = bias_variable([1164])\n",
    "\n",
    "h_conv5_flat_ln = tf.reshape(h_conv5_ln, [-1, 1152])\n",
    "h_fc1_ln = tf.nn.relu(tf.matmul(h_conv5_flat_ln, W_fc1_ln) + b_fc1_ln)\n",
    "\n",
    "keep_prob_ln = tf.placeholder(tf.float32,name=\"keep_prob_ln\")\n",
    "h_fc1_drop_ln = tf.nn.dropout(h_fc1_ln, keep_prob_ln)\n",
    "\n",
    "#FCL 2\n",
    "W_fc2_ln = weight_variable([1164, 100])\n",
    "b_fc2_ln = bias_variable([100])\n",
    "\n",
    "h_fc2_ln = tf.nn.relu(tf.matmul(h_fc1_drop_ln, W_fc2_ln) + b_fc2_ln)\n",
    "\n",
    "h_fc2_drop_ln = tf.nn.dropout(h_fc2_ln, keep_prob_ln)\n",
    "\n",
    "#FCL 3\n",
    "W_fc3_ln = weight_variable([100, 50])\n",
    "b_fc3_ln = bias_variable([50])\n",
    "\n",
    "h_fc3_ln = tf.nn.relu(tf.matmul(h_fc2_drop_ln, W_fc3_ln) + b_fc3_ln)\n",
    "\n",
    "h_fc3_drop_ln = tf.nn.dropout(h_fc3_ln, keep_prob_ln)\n",
    "\n",
    "#FCL 3\n",
    "W_fc4_ln = weight_variable([50, 10])\n",
    "b_fc4_ln = bias_variable([10])\n",
    "\n",
    "h_fc4_ln = tf.nn.relu(tf.matmul(h_fc3_drop_ln, W_fc4_ln) + b_fc4_ln)\n",
    "\n",
    "h_fc4_drop_ln = tf.nn.dropout(h_fc4_ln, keep_prob_ln)\n",
    "\n",
    "#Output\n",
    "W_fc5_ln = weight_variable([10, 1])\n",
    "b_fc5_ln = bias_variable([1])\n",
    "\n",
    "# linear activation function\n",
    "predicted_angle_ln = tf.identity((tf.matmul(h_fc4_drop_ln, W_fc5_ln) + b_fc5_ln))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_pointer = 0\n",
    "test_batch_pointer = 0\n",
    "\n",
    "# Utility Functions\n",
    "def LoadTrainBatch(batch_size):\n",
    "    global train_batch_pointer\n",
    "    x_out = []\n",
    "    y_out = []\n",
    "    for i in range(0, batch_size):\n",
    "        x_out.append(scipy.misc.imresize(scipy.misc.imread(train_images[(train_batch_pointer + i) % num_of_train_images])[-150:], \n",
    "                                         [66, 200]) / 255.0)\n",
    "        y_out.append([train_angle[(train_batch_pointer + i) % num_of_train_images]])\n",
    "    train_batch_pointer += batch_size\n",
    "    return x_out, y_out\n",
    "\n",
    "def LoadTestBatch(batch_size): \n",
    "    global test_batch_pointer\n",
    "    x_out = []\n",
    "    y_out = []\n",
    "    for i in range(0, batch_size):\n",
    "        x_out.append(scipy.misc.imresize(scipy.misc.imread(test_images[(test_batch_pointer + i) % num_of_test_images])[-150:], \n",
    "                                         [66, 200]) / 255.0)\n",
    "        y_out.append([test_angle[(test_batch_pointer + i) % num_of_test_images]])\n",
    "    test_batch_pointer += batch_size\n",
    "    return x_out, y_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVEDIR = \"/home/ajay/Applied_course/self_driving_car/Autopilot-TensorFlow-master/save/\"\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Step: 450, Loss: 0.440863\n",
      "Model saved in file: /home/ajay/Applied_course/self_driving_car/Autopilot-TensorFlow-master/save/model.ckpt\n",
      "()\n",
      "Epoch: 1, Step: 550, Loss: 0.108497\n",
      "Model saved in file: /home/ajay/Applied_course/self_driving_car/Autopilot-TensorFlow-master/save/model.ckpt\n",
      "()\n",
      "Epoch: 2, Step: 650, Loss: 0.0525254\n",
      "Model saved in file: /home/ajay/Applied_course/self_driving_car/Autopilot-TensorFlow-master/save/model.ckpt\n",
      "()\n",
      "Epoch: 3, Step: 750, Loss: 0.0241816\n",
      "Model saved in file: /home/ajay/Applied_course/self_driving_car/Autopilot-TensorFlow-master/save/model.ckpt\n",
      "()\n",
      "Epoch: 4, Step: 850, Loss: 0.0695357\n",
      "Model saved in file: /home/ajay/Applied_course/self_driving_car/Autopilot-TensorFlow-master/save/model.ckpt\n",
      "()\n",
      "Epoch: 5, Step: 950, Loss: 0.0288018\n",
      "Model saved in file: /home/ajay/Applied_course/self_driving_car/Autopilot-TensorFlow-master/save/model.ckpt\n",
      "()\n",
      "Epoch: 6, Step: 1050, Loss: 0.0115439\n",
      "Model saved in file: /home/ajay/Applied_course/self_driving_car/Autopilot-TensorFlow-master/save/model.ckpt\n",
      "()\n",
      "Epoch: 7, Step: 1150, Loss: 4.02123\n",
      "Model saved in file: /home/ajay/Applied_course/self_driving_car/Autopilot-TensorFlow-master/save/model.ckpt\n",
      "()\n",
      "Epoch: 8, Step: 1250, Loss: 0.287714\n",
      "Model saved in file: /home/ajay/Applied_course/self_driving_car/Autopilot-TensorFlow-master/save/model.ckpt\n",
      "()\n",
      "Epoch: 9, Step: 1350, Loss: 0.0400232\n",
      "Model saved in file: /home/ajay/Applied_course/self_driving_car/Autopilot-TensorFlow-master/save/model.ckpt\n",
      "()\n",
      "Epoch: 10, Step: 1450, Loss: 0.00147111\n",
      "Model saved in file: /home/ajay/Applied_course/self_driving_car/Autopilot-TensorFlow-master/save/model.ckpt\n",
      "()\n",
      "Epoch: 11, Step: 1550, Loss: 0.926532\n",
      "Model saved in file: /home/ajay/Applied_course/self_driving_car/Autopilot-TensorFlow-master/save/model.ckpt\n",
      "()\n",
      "Epoch: 12, Step: 1650, Loss: 0.00357259\n",
      "Model saved in file: /home/ajay/Applied_course/self_driving_car/Autopilot-TensorFlow-master/save/model.ckpt\n",
      "()\n",
      "Epoch: 13, Step: 1750, Loss: 0.0619213\n",
      "Model saved in file: /home/ajay/Applied_course/self_driving_car/Autopilot-TensorFlow-master/save/model.ckpt\n",
      "()\n",
      "Epoch: 14, Step: 1850, Loss: 0.520679\n",
      "Model saved in file: /home/ajay/Applied_course/self_driving_car/Autopilot-TensorFlow-master/save/model.ckpt\n",
      "()\n",
      "Epoch: 15, Step: 1950, Loss: 0.124303\n",
      "Model saved in file: /home/ajay/Applied_course/self_driving_car/Autopilot-TensorFlow-master/save/model.ckpt\n",
      "()\n",
      "Epoch: 16, Step: 2050, Loss: 0.0283689\n",
      "Model saved in file: /home/ajay/Applied_course/self_driving_car/Autopilot-TensorFlow-master/save/model.ckpt\n",
      "()\n",
      "Epoch: 17, Step: 2150, Loss: 0.0294688\n",
      "Model saved in file: /home/ajay/Applied_course/self_driving_car/Autopilot-TensorFlow-master/save/model.ckpt\n",
      "()\n",
      "Epoch: 18, Step: 2250, Loss: 0.219354\n",
      "Model saved in file: /home/ajay/Applied_course/self_driving_car/Autopilot-TensorFlow-master/save/model.ckpt\n",
      "()\n",
      "Epoch: 19, Step: 2350, Loss: 0.113417\n",
      "Model saved in file: /home/ajay/Applied_course/self_driving_car/Autopilot-TensorFlow-master/save/model.ckpt\n",
      "()\n",
      "Epoch: 20, Step: 2450, Loss: 0.026536\n",
      "Model saved in file: /home/ajay/Applied_course/self_driving_car/Autopilot-TensorFlow-master/save/model.ckpt\n",
      "()\n",
      "Epoch: 21, Step: 2550, Loss: 0.0117085\n",
      "Model saved in file: /home/ajay/Applied_course/self_driving_car/Autopilot-TensorFlow-master/save/model.ckpt\n",
      "()\n",
      "Epoch: 22, Step: 2650, Loss: 0.00776918\n",
      "Model saved in file: /home/ajay/Applied_course/self_driving_car/Autopilot-TensorFlow-master/save/model.ckpt\n",
      "()\n",
      "Epoch: 23, Step: 2750, Loss: 0.211507\n",
      "Model saved in file: /home/ajay/Applied_course/self_driving_car/Autopilot-TensorFlow-master/save/model.ckpt\n",
      "()\n",
      "Epoch: 24, Step: 2850, Loss: 0.0135412\n",
      "Model saved in file: /home/ajay/Applied_course/self_driving_car/Autopilot-TensorFlow-master/save/model.ckpt\n",
      "()\n",
      "Epoch: 25, Step: 2950, Loss: 0.0119389\n",
      "Model saved in file: /home/ajay/Applied_course/self_driving_car/Autopilot-TensorFlow-master/save/model.ckpt\n",
      "()\n",
      "Epoch: 26, Step: 3050, Loss: 0.273607\n",
      "Model saved in file: /home/ajay/Applied_course/self_driving_car/Autopilot-TensorFlow-master/save/model.ckpt\n",
      "()\n",
      "Epoch: 27, Step: 3150, Loss: 0.0159948\n",
      "Model saved in file: /home/ajay/Applied_course/self_driving_car/Autopilot-TensorFlow-master/save/model.ckpt\n",
      "()\n",
      "Epoch: 28, Step: 3250, Loss: 0.00526949\n",
      "Model saved in file: /home/ajay/Applied_course/self_driving_car/Autopilot-TensorFlow-master/save/model.ckpt\n",
      "()\n",
      "Epoch: 29, Step: 3350, Loss: 0.585739\n",
      "Model saved in file: /home/ajay/Applied_course/self_driving_car/Autopilot-TensorFlow-master/save/model.ckpt\n",
      "()\n",
      "Run the command line:\n",
      "--> tensorboard --logdir=./logs \n",
      "Then open http://0.0.0.0:6006/ into your web browser\n"
     ]
    }
   ],
   "source": [
    "start = datetime.now()\n",
    "L2NormConst = 0.001\n",
    "\n",
    "train_vars = tf.trainable_variables()\n",
    "\n",
    "loss = tf.reduce_mean(tf.square(tf.subtract(true_angle_ln, predicted_angle_ln))) + tf.add_n([tf.nn.l2_loss(v) for v in train_vars]) * L2NormConst\n",
    "train_step = tf.train.AdamOptimizer(1e-3).minimize(loss)\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# create a summary to monitor cost tensor\n",
    "tf.summary.scalar(\"loss\", loss)\n",
    "\n",
    "# merge all summaries into a single op\n",
    "merged_summary_op =  tf.summary.merge_all()\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# op to write logs to Tensorboard\n",
    "logs_path = './logs'\n",
    "summary_writer = tf.summary.FileWriter(logs_path, graph=tf.get_default_graph())\n",
    "\n",
    "epochs = 30\n",
    "batch_size = 100\n",
    "\n",
    "# train over the dataset about 30 times\n",
    "previous_i = 0\n",
    "previous_loss = 0\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for i in range(int(num_of_images/batch_size)):        \n",
    "        xs, ys = LoadTrainBatch(batch_size)\n",
    "        train_step.run(feed_dict={true_image_ln: xs, true_angle_ln: ys, keep_prob_ln: 0.50})\n",
    "        if i % 10 == 0:            \n",
    "            xs, ys = LoadTestBatch(batch_size)\n",
    "            loss_value = loss.eval(feed_dict={true_image_ln:xs, true_angle_ln: ys, keep_prob_ln: 1.0})\n",
    "            previous_loss = loss_value\n",
    "            previous_i = i\n",
    "            # print(\"Epoch: %d, Step: %d, Loss: %g\" % (epoch, epoch * batch_size + i, loss_value))\n",
    "\n",
    "        # write logs at every iteration\n",
    "        summary = merged_summary_op.eval(feed_dict={true_image_ln:xs, true_angle_ln: ys, keep_prob_ln: 1.0})\n",
    "        summary_writer.add_summary(summary, epoch * num_of_images/batch_size + i)\n",
    "\n",
    "        if i % batch_size == 0:\n",
    "            if not os.path.exists(SAVEDIR):\n",
    "                os.makedirs(SAVEDIR)            \n",
    "            checkpoint_path = os.path.join(SAVEDIR, \"model.ckpt\")\n",
    "            filename = saver.save(sess, checkpoint_path)    \n",
    "    print(\"Epoch: %d, Step: %d, Loss: %g\" % (epoch, epoch * batch_size + previous_i, previous_loss)) \n",
    "    print(\"Model saved in file: %s\" % filename)\n",
    "    print()\n",
    "\n",
    "print(\"Run the command line:\\n\" \\\n",
    "          \"--> tensorboard --logdir=./logs \" \\\n",
    "          \"\\nThen open http://0.0.0.0:6006/ into your web browser\")\n",
    "\n",
    "print(\"\\nTime taken to train the model: \")\n",
    "print(datetime.now() - start)\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Making prediction from model</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run model for testing run test_output.py in command prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "Self_driving_car.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
